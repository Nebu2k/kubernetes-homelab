# Kubernetes Homelab - GitOps with ArgoCD

Production-ready K3s cluster managed via GitOps using ArgoCD App-of-Apps pattern.

## üéØ Architecture

**Key Principle**: ArgoCD manages everything EXCEPT itself (prevents self-management conflicts).

### Deployment Flow

```text
1. Manual: K3s + Kube-VIP ‚Üí HA Control Plane
2. Manual: ArgoCD via Helm ‚Üí GitOps Engine
3. GitOps: bootstrap/root-app.yaml ‚Üí App-of-Apps
4. GitOps: Everything else deployed automatically with Sync-Waves
```

### Sync-Wave Order

| Wave | Component |
|------|-----------|
{% for wave, components in sync_waves.items() -%}
| {{ wave }} | {{ components | join(', ') | title | replace('-', ' ') }} |
{% endfor %}
## üìÅ Repository Structure

```text
{{ repo_structure }}
```

## üöÄ Fresh Installation

### Prerequisites

- 2+ nodes
- Domain (any DNS provider)
- Pangolin API credentials (for SSL/TLS certificates)
- S3-compatible storage for Longhorn backups (optional)

### Step 1: Install K3s Cluster (**on raspi4**)

**First control plane node:**

```bash
curl -sfL https://get.k3s.io | INSTALL_K3S_CHANNEL=stable sh -s - server \
  --cluster-init \
  --tls-san 192.168.2.249 \
  --tls-san raspi4 \
  --tls-san 192.168.2.2 \
  --disable traefik \
  --write-kubeconfig-mode 644

# Save token for additional nodes
sudo cat /var/lib/rancher/k3s/server/node-token
```

### Step 2: Install Kube-VIP (**on raspi4** - Control Plane HA)

```bash
kubectl apply -f https://kube-vip.io/manifests/rbac.yaml

cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: kube-vip-ds
  namespace: kube-system
spec:
  selector:
    matchLabels:
      name: kube-vip-ds
  template:
    metadata:
      labels:
        name: kube-vip-ds
    spec:
      hostNetwork: true
      nodeSelector:
        node-role.kubernetes.io/control-plane: "true"
      serviceAccountName: kube-vip
      containers:
      - name: kube-vip
        image: ghcr.io/kube-vip/kube-vip:v1.0.1
        args: ["manager"]
        env:
        - name: vip_arp
          value: "true"
        - name: port
          value: "6443"
        - name: vip_cidr
          value: "32"
        - name: cp_enable
          value: "true"
        - name: cp_namespace
          value: kube-system
        - name: vip_leaderelection
          value: "true"
        - name: address
          value: "192.168.2.249"  # TODO: Your VIP
        securityContext:
          capabilities:
            add: ["NET_ADMIN", "NET_RAW"]
      tolerations:
      - effect: NoSchedule
        operator: Exists
      - effect: NoExecute
        operator: Exists
EOF

# Wait for Kube-VIP to be ready
sleep 10

# Test VIP
ping -c 3 192.168.2.249
```

### Step 3: Configure kubectl with VIP (**on your laptop**)

```bash
scp raspi4:/etc/rancher/k3s/k3s.yaml ~/.kube/config
sed -i '' 's/127.0.0.1/192.168.2.249/g' ~/.kube/config
kubectl get nodes
```

### Step 4: Join Additional Control Plane Nodes (**on raspi5**)

```bash
# Join via VIP (not node IP!)
curl -sfL https://get.k3s.io | INSTALL_K3S_CHANNEL=stable sh -s - server \
  --server https://192.168.2.249:6443 \
  --token <token-from-step-1> \
  --tls-san 192.168.2.249 \
  --tls-san raspi5 \
  --tls-san 192.168.2.9 \
  --disable traefik \
  --write-kubeconfig-mode 644
```

### Step 4.5: Join Worker Nodes with Longhorn Storage (**on k3s-worker-1**)

**Prerequisites:**

- Second disk installed (e.g., 2TB NVMe for Longhorn storage)
- Static IP configured via DHCP reservation in router

**1. Install system essentials:**

```bash
sudo apt update && sudo apt upgrade -y
sudo apt install -y curl wget git vim htop net-tools iptables qemu-guest-agent
sudo systemctl start qemu-guest-agent
```

**2. Prepare second disk for Longhorn:**

```bash
# Identify disk (usually /dev/sdb for second disk)
lsblk

# Format disk with ext4
sudo mkfs.ext4 -L longhorn-storage /dev/sdb

# Create Longhorn mountpoint
sudo mkdir -p /var/lib/longhorn

# Get UUID for permanent mounting
sudo blkid /dev/sdb

# Add to fstab (replace <uuid> with actual UUID from blkid)
echo "UUID=<uuid> /var/lib/longhorn ext4 defaults,noatime 0 2" | sudo tee -a /etc/fstab

# Mount and verify
sudo mount -a
df -h /var/lib/longhorn
```

**3. Join as K3s worker:**

```bash
curl -sfL https://get.k3s.io | K3S_URL=https://192.168.2.249:6443 \
  K3S_TOKEN=<token-from-step-1> \
  sh -
```

‚ö†Ô∏è **For Multipass VMs with multiple network interfaces:**

If the VM has both a NAT interface (e.g., 192.168.64.x) and a bridged interface (e.g., 192.168.2.x), explicitly specify the correct interface:

```bash
curl -sfL https://get.k3s.io | K3S_URL=https://192.168.2.249:6443 \
  K3S_TOKEN=<token-from-step-1> \
  INSTALL_K3S_EXEC="--node-ip=<bridged-ip> --flannel-iface=ens4" \
  sh -
```

Replace `<bridged-ip>` with the IP from your cluster network (e.g., 192.168.2.x) and adjust `ens4` to match your bridged interface name (check with `ip addr show`).

**4. Label node as worker (from your laptop):**

```bash
kubectl label node k3s-worker-1 node-role.kubernetes.io/worker=worker
```

**5. Verify Longhorn detects storage:**

```bash
# From your laptop
kubectl get nodes
kubectl get pods -n longhorn-system -o wide | grep k3s-worker-1

# Check Longhorn UI (http://longhorn.elmstreet79.de)
# Node ‚Üí k3s-worker-1 ‚Üí should show full disk capacity
```

‚ö†Ô∏è **Note:** Longhorn automatically detects `/var/lib/longhorn` - no additional configuration needed!

### Step 5: Install ArgoCD via Helm (**on your laptop**)

‚ö†Ô∏è **ArgoCD is NOT managed via GitOps** (prevents self-management conflicts)

```bash
helm repo add argo https://argoproj.github.io/argo-helm
helm repo update

# Install with your domain
# Note: Installs latest version (no --version flag)
helm install argocd argo/argo-cd \
  --namespace argocd \
  --create-namespace \
  --set global.domain=argocd.elmstreet79.de \
  --set configs.cm.url=https://argocd.elmstreet79.de \
  --set 'configs.params.server\.insecure'=true

# Wait for ArgoCD to be ready
kubectl wait --for=condition=available --timeout=300s \
  deployment/argocd-server -n argocd

# Get admin password
kubectl -n argocd get secret argocd-initial-admin-secret \
  -o jsonpath="{.data.password}" | base64 -d && echo
```

**Why `server.insecure=true`?**

- ArgoCD runs on HTTP internally
- Traefik terminates TLS
- Prevents redirect loops

**Note:** If you changed the domain in Step 5, update the Helm values accordingly.

### Step 6: Fork & Configure Repository (**on your laptop**)

```bash
# Fork https://github.com/Nebu2k/kubernetes-homelab
git clone https://github.com/YOUR_USERNAME/kubernetes-homelab
cd kubernetes-homelab

# Install Git hooks (enables auto-README regeneration on commit)
.githooks/install.sh
```

**‚öôÔ∏è Configure for your environment:**

> ‚ö†Ô∏è **Warning:** The repository is pre-configured for `elmstreet79.de`. If using your own domain, update:

1. **MetalLB IP Pool** (adjust to your network):

   ```bash
   vim manifests/metallb/metallb-ip-pool.yaml
   # Change: 192.168.2.250-192.168.2.253
   ```

2. **Pangolin API Credentials** (required):

   ```bash
   # Create from example
   cp manifests/pangolin-sync/pangolin-api-credentials-unsealed.yaml.example \
      manifests/pangolin-sync/pangolin-api-credentials-unsealed.yaml
   
   # Add your Pangolin API credentials
   vim manifests/pangolin-sync/pangolin-api-credentials-unsealed.yaml
   # Update: API_KEY, ORG_ID, SITE_ID, DOMAIN_ID, DOMAIN_SUFFIX
   
   # Note: Sealing happens AFTER cluster bootstrap (Step 7+)
   # For now, keep it unsealed locally (gitignored)
   ```

3. **Longhorn S3 Backup** (optional):

   ```bash
   # Create from example
   cp manifests/longhorn/s3-secret-unsealed.yaml.example \
      manifests/longhorn/s3-secret-unsealed.yaml
   
   # Update MinIO/S3 credentials
   vim manifests/longhorn/s3-secret-unsealed.yaml
   # Change: AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_ENDPOINTS
   
   # Note: Sealing happens AFTER cluster bootstrap (Step 7+)
   # For now, keep it unsealed locally (gitignored)
   ```

   ‚ö†Ô∏è **Note:** `*-unsealed.yaml` files are gitignored for security. Only `.example` templates are committed.

4. **Traefik Dashboard Domain** (required if using different domain):

   The Traefik dashboard is configured in the Helm values file:

   ```bash
   vim manifests/traefik/values.yaml
   # Update line 45: matchRule: Host(`traefik.your-domain.com`)
   # Update annotations with your domain
   ```

**Commit and push:**

```bash
git add -A
git commit -m "Configure for my environment"
git push
```

### Step 7: Bootstrap GitOps (**on your laptop**)

```bash
# Deploy App-of-Apps
kubectl apply -f bootstrap/root-app.yaml

# Watch ArgoCD deploy everything (~5-10 minutes)
kubectl get applications -n argocd -w
```

**What happens:**

- Sealed Secrets Controller installs first (Sync-Wave 0)
- MetalLB, Pangolin, Traefik, etc. follow in order
- Some apps will stay "Progressing" until secrets are sealed (next step)

### Step 7.5: Seal Secrets (**on your laptop** - AFTER Step 7)

‚ö†Ô∏è **Wait until Sealed Secrets Controller is ready:**

```bash
# Check if controller is running
kubectl wait --for=condition=available --timeout=300s \
  deployment/sealed-secrets-controller -n kube-system
```

**Option A: Download public certificate for offline sealing (Recommended)**

This allows you to seal secrets even when not connected to the cluster:

```bash
# Download the public certificate (one-time setup)
kubeseal --fetch-cert --controller-namespace=kube-system > sealed-secrets-pub-cert.pem

# Seal Pangolin API credentials
kubeseal --cert sealed-secrets-pub-cert.pem --format=yaml \
  < manifests/pangolin-sync/pangolin-api-credentials-unsealed.yaml \
  > manifests/pangolin-sync/pangolin-api-credentials-sealed.yaml

# If using Longhorn S3 backup:
kubeseal --cert sealed-secrets-pub-cert.pem --format=yaml \
  < manifests/longhorn/minio-secret-unsealed.yaml \
  > manifests/longhorn/minio-secret-sealed.yaml
```

**Option B: Seal directly from cluster** (requires cluster access):

```bash
# Seal Pangolin API credentials
kubeseal --format=yaml --controller-namespace=kube-system \
  < manifests/pangolin-sync/pangolin-api-credentials-unsealed.yaml \
  > manifests/pangolin-sync/pangolin-api-credentials-sealed.yaml

# If using Longhorn S3 backup:
kubeseal --format=yaml --controller-namespace=kube-system \
  < manifests/longhorn/minio-secret-unsealed.yaml \
  > manifests/longhorn/minio-secret-sealed.yaml
```

**Commit and deploy:**

```bash
# Commit and push
git add manifests/*/kustomization.yaml
git add manifests/*/*-sealed.yaml
git commit -m "üîê Add sealed secrets"
git push

# ArgoCD will auto-sync and apply the secrets
kubectl get applications -n argocd -w
```

‚ö†Ô∏è **Note:** The public certificate (`sealed-secrets-pub-cert.pem`) is cluster-specific. If you rebuild the cluster or reinstall Sealed Secrets, you'll need to fetch a new certificate. The certificate file is gitignored for security.

### Step 7.6: Configure Homepage Widgets (**on your laptop** - AFTER Grafana is ready)

**Create sealed secrets for Homepage widgets:**

‚ö†Ô∏è **Important:** For each widget secret, copy the example file, edit with your credentials, then seal it.

```bash
{% for secret in homepage_secrets %}
# {{ loop.index }}. {{ secret.base_name | replace('-', ' ') | title }}
cp manifests/homepage/{{ secret.example_file }} \
   manifests/homepage/{{ secret.unsealed_file }}

# Edit the file and replace placeholder values with your actual credentials
vim manifests/homepage/{{ secret.unsealed_file }}

# Seal the secret (using offline certificate)
kubeseal --cert sealed-secrets-pub-cert.pem --format=yaml \
  < manifests/homepage/{{ secret.unsealed_file }} \
  > manifests/homepage/{{ secret.sealed_file }}

{% endfor %}
# Commit and push
git add manifests/homepage/*-sealed.yaml
git commit -m "Add Homepage widget credentials"
git push
```

‚ö†Ô∏è **Note:** If you rebuild the cluster, passwords may change (e.g., Grafana admin password), so you'll need to recreate the affected sealed secrets.

### Step 8: Verify Deployment (**on your laptop**)

```bash
# All apps should be Synced + Healthy
kubectl get applications -n argocd

# MetalLB assigned LoadBalancer IP
kubectl get svc -n traefik
# EXTERNAL-IP should show 192.168.2.250

# Ingresses configured
kubectl get ingress -A
```

### Step 9: Access UIs (**from your laptop browser**)

‚ö†Ô∏è **All Services**: Services annotated with `pangolin.io/expose: "true"` are automatically registered in Pangolin for external HTTPS access with SSL certificates!

- **With Authentication**: Services with `pangolin.io/auth: "true"` require Pangolin authentication
- **Without Authentication**: Services without auth annotation are directly accessible from the internet

**ArgoCD:**

```text
URL: https://argocd.elmstreet79.de
User: admin
Pass: <from-step-5>
```

‚ö†Ô∏è **Change password immediately!**

1. User Info ‚Üí Update Password
2. Then delete initial secret:

```bash
kubectl -n argocd delete secret argocd-initial-admin-secret
```

**Portainer:**

```text
URL: https://portainer.elmstreet79.de
```

‚ö†Ô∏è **Create admin account within 5 minutes!**

If timeout, restart the pod:

```bash
kubectl delete pod -n portainer -l app.kubernetes.io/name=portainer
```

**Longhorn:**

```text
URL: https://longhorn.elmstreet79.de
(via Pangolin)
```

**Homepage (Homelab Dashboard):**

```text
URL: https://home.elmstreet79.de
```

üè† **Features:** Unified dashboard with links to all services, real-time Kubernetes cluster metrics, auto-discovery of ingresses, dark theme, widgets for Proxmox/ArgoCD/Grafana

**Uptime Kuma (Uptime Monitoring):**

```text
URL: https://uptime.elmstreet79.de
```

‚ö†Ô∏è **First visit:** Create admin account on initial access. Then add monitors for your services.

**Service Access Architecture:**

All services are accessible via Pangolin's secure network infrastructure:

**Pangolin-Exposed Services:**

- **Filter Logic**: Ingresses/Services WITH `pangolin.io/expose: "true"` annotation
- **Access**: Publicly accessible from the internet with automatic SSL/TLS certificates
- **Authentication**:
  - `pangolin.io/auth: "true"` ‚Üí Requires Pangolin authentication (secure, private access)
  - `pangolin.io/auth: "false"` or no auth annotation ‚Üí Directly accessible without authentication

**Pangolin Sync Automation:**

- **PostSync Hook**: Runs automatically after every ArgoCD sync
- **CronJob**: Fallback every 5 minutes
- **Pangolin API**: Registers resources in Pangolin network for secure external access
- **Auto-Cleanup**: Removes orphaned resources when Ingresses/Services are deleted
- **SSL/TLS**: Pangolin provides automatic SSL certificates for all exposed services

**All Pangolin-Exposed Services:**

```text
# Services with Pangolin authentication required (pangolin.io/auth: "true"):
{% for service in pangolin_services.with_auth -%}
{{ service.name }}: {{ service.url }}
{% endfor %}
# Services publicly accessible without authentication (pangolin.io/auth: "false"):
{% for service in pangolin_services.without_auth -%}
{{ service.name }}: {{ service.url }}
{% endfor %}
```

## üîß Management

### View Application Status

```bash
kubectl get applications -n argocd
kubectl describe application <app-name> -n argocd
```

### Update Component

```bash
# Check for latest Helm chart version
helm repo update
helm search repo <chart-name> --versions | head -n 5

# Example: Check traefik latest version
helm search repo traefik/traefik --versions | head -n 5

# Edit Helm values
vim manifests/traefik/values.yaml

# Commit and push - ArgoCD auto-syncs
git add manifests/traefik/values.yaml
git commit -m "Update Traefik to 2 replicas"
git push

# Watch sync
kubectl get application traefik -n argocd -w
```

### Update Secrets

```bash
# 1. Edit unsealed secret
vim manifests/pangolin-sync/pangolin-api-credentials-unsealed.yaml

# 2. Re-seal (using offline certificate)
kubeseal --cert sealed-secrets-pub-cert.pem --format=yaml \
  < manifests/pangolin-sync/pangolin-api-credentials-unsealed.yaml \
  > manifests/pangolin-sync/pangolin-api-credentials-sealed.yaml

# 3. Commit and push
git add manifests/pangolin-sync/pangolin-api-credentials-sealed.yaml
git commit -m "Rotate Pangolin API credentials"
git push
```

**Alternative: Seal directly from cluster** (if you don't have the certificate):

```bash
# Re-seal (requires cluster connection)
kubeseal --format=yaml --controller-namespace=kube-system \
  < manifests/pangolin-sync/pangolin-api-credentials-unsealed.yaml \
  > manifests/pangolin-sync/pangolin-api-credentials-sealed.yaml
```

### Force Sync Application

```bash
# Via kubectl
kubectl patch application <app-name> -n argocd --type merge \
  -p '{"operation":{"initiatedBy":{"username":"manual"}}}'

# Via ArgoCD CLI
argocd app sync <app-name>
```

### Hard Refresh Application

Sometimes ArgoCD needs a complete reset (e.g., stuck state, CRD issues):

```bash
# Delete and re-create the ArgoCD Application (doesn't delete K8s resources)
kubectl delete application <app-name> -n argocd && sleep 2 && \
  kubectl apply -f apps/<app-name>.yaml

# Example: Hard refresh Longhorn
kubectl delete application longhorn -n argocd && sleep 2 && \
  kubectl apply -f apps/longhorn.yaml
```

**Note:** This only resets the ArgoCD Application object, not the actual Kubernetes resources. Useful for clearing stuck sync states or comparison errors.

## üêõ Troubleshooting

### MetalLB Not Assigning IPs

**Check:**

```bash
kubectl logs -n metallb-system -l app.kubernetes.io/component=speaker
```

**Should NOT show:**

```text
"error":"assigned IP not allowed by config"
```

**Fix:** Ensure L2Advertisement exists in `manifests/metallb/metallb-ip-pool.yaml`

### ArgoCD App OutOfSync

**Check:**

```bash
kubectl describe application <app-name> -n argocd
kubectl logs -n argocd deployment/argocd-application-controller
```

**Force refresh:**

```bash
argocd app sync <app-name> --force
```

### Grafana Widget Not Showing on Homepage

**Check:**

```bash
# 1. Verify Homepage has the environment variables
kubectl get deployment homepage -n homepage -o yaml | grep -E "GRAFANA_(USERNAME|PASSWORD)"

# 2. Check if secret exists and has correct fields
kubectl get secret homepage-grafana -n homepage -o yaml

# 3. Check Homepage logs
kubectl logs -n homepage deployment/homepage

# 4. Verify credentials are set correctly
kubectl get secret homepage-grafana -n homepage -o yaml
```

**Fix if credentials are invalid:**

Re-create the sealed secret as described in Step 7.6.

### Unseal a Sealed Secret (for debugging)

If you need to view the decrypted content of a sealed secret:

```bash
# Get the sealed secret from the cluster
kubectl get sealedsecret <sealed-secret-name> -n <namespace> -o yaml > sealed.yaml

# The sealed secret will be automatically decrypted by the controller and stored as a regular Secret
# View the decrypted secret
kubectl get secret <secret-name> -n <namespace> -o yaml

# Decode a specific field (e.g., password)
kubectl get secret <secret-name> -n <namespace> -o jsonpath='{.data.password}' | base64 -d

# Example: View Grafana admin password
kubectl get secret -n monitoring grafana-admin-credentials \
  -o jsonpath="{.data.admin-password}" | base64 -d && echo
```

‚ö†Ô∏è **Note:** You cannot "unseal" the encrypted data in the SealedSecret YAML file without access to the cluster's private key. The Sealed Secrets controller automatically decrypts SealedSecrets into regular Secrets when applied to the cluster.

## üìö Components

| Component | Version | Purpose |
|-----------|---------|---------|
{% for name, info in versions.items() -%}
| {{ info.chart | title | replace('-', ' ') }} | {{ info.version }} | {{ name | replace('-', ' ') | title }} |
{% endfor -%}
| K3s | v1.33.5 | Lightweight Kubernetes |
| Kube-VIP | v1.0.1 | Control plane HA |
| ArgoCD | v3.2.3 | Continuous Delivery |

## üìñ Documentation

{% for name, url in documentation_links.items() -%}
- [{{ name }}]({{ url }})
{% endfor %}
## üìù License

MIT

---

> ü§ñ **This README is auto-generated** using `docs-generator/generate_readme.py`  
> To regenerate manually: `make docs`  
> Auto-generation on commit: Enabled via `.githooks/pre-commit` (run `.githooks/install.sh` after clone)

