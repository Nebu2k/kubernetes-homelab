# kube-prometheus-stack Helm values
# Optimized for Raspberry Pi homelab

# Global settings
defaultRules:
  create: true
  rules:
    alertmanager: true
    etcd: false  # K3s uses embedded SQLite by default
    kubeScheduler: false  # K3s scheduler metrics not exposed
    kubeControllerManager: false  # K3s controller metrics not exposed
    kubeProxy: false  # K3s uses kube-router instead of kube-proxy

# Disable K3s components that don't expose metrics
kubeScheduler:
  enabled: false
kubeControllerManager:
  enabled: false
kubeProxy:
  enabled: false
kubeEtcd:
  enabled: false

# Prometheus configuration
prometheus:
  
  prometheusSpec:
    # Use EndpointSlice instead of deprecated Endpoints API (required for Kubernetes v1.33+)
    discoveryRole: endpointslice
    
    # Resource limits (conservative for Pi)
    resources:
      requests:
        cpu: 200m
        memory: 512Mi
      limits:
        cpu: 1000m
        memory: 2Gi
    
    # Run on worker nodes only
    nodeSelector:
      node-role.kubernetes.io/worker: worker
    
    # Storage configuration
    storageSpec:
      volumeClaimTemplate:
        metadata:
          annotations:
            recurring-job.longhorn.io/source: disabled
        spec:
          storageClassName: longhorn
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 40Gi
    
    # Retention policy
    retention: 30d
    retentionSize: "30GB"
    
    # Service monitors
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false

# Grafana configuration
grafana:
  enabled: true
  
  # Admin credentials (change in production!)
  adminPassword: prom-operator
  
  # Run on worker nodes only
  nodeSelector:
    node-role.kubernetes.io/worker: worker
  
  # Persistence
  persistence:
    enabled: true
    storageClassName: longhorn
    size: 5Gi
  
  # Ingress will be configured in manifests
  ingress:
    enabled: false
  
  # Resources (conservative for Pi)
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 512Mi
  
  # Pre-installed dashboards
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
      - name: 'default'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        editable: true
        options:
          path: /var/lib/grafana/dashboards/default
  
  # Additional dashboards
  dashboards:
    default:
      # Kubernetes cluster overview
      kubernetes-cluster:
        gnetId: 7249
        revision: 1
        datasource: Prometheus
      # Node exporter full
      node-exporter:
        gnetId: 1860
        revision: 31
        datasource: Prometheus
      # Longhorn dashboard
      longhorn:
        gnetId: 13032
        revision: 6
        datasource: Prometheus
      # NGINX Ingress Controller
      nginx-ingress:
        gnetId: 9614
        revision: 1
        datasource: Prometheus
      # UniFi Poller - Client Insights
      unifi-client-insights:
        gnetId: 11315
        revision: 9
        datasource: Prometheus
      # UniFi Poller - Network Sites
      unifi-sites:
        gnetId: 11311
        revision: 5
        datasource: Prometheus
      # UniFi Poller - UAP Insights
      unifi-uap:
        gnetId: 11314
        revision: 10
        datasource: Prometheus
      # UniFi Poller - USW Insights
      unifi-usw:
        gnetId: 11312
        revision: 9
        datasource: Prometheus
      # Proxmox via Prometheus
      proxmox-prometheus:
        gnetId: 24550
        revision: 1
        datasource: Prometheus

# Alert Manager
alertmanager:
  enabled: true
  
  # Alertmanager configuration for SNS notifications
  config:
    global:
      resolve_timeout: 5m
    
    route:
      group_by: ['alertname', 'cluster', 'severity']
      group_wait: 10s
      group_interval: 5m
      repeat_interval: 4h
      receiver: 'sns-receiver'
      routes:
        # Watchdog - silence (always firing, no notification needed)
        - match:
            alertname: Watchdog
          receiver: 'null'
        # InfoInhibitor - silence (meta-alert for info-level inhibition)
        - match:
            alertname: InfoInhibitor
          receiver: 'null'
        # Critical alerts - immediate notification
        - match:
            severity: critical
          receiver: 'sns-receiver'
          continue: true
        # Warning alerts - grouped notification
        - match:
            severity: warning
          receiver: 'sns-receiver'
          group_wait: 30s
    
    receivers:
      - name: 'null'  # No notifications (for Watchdog)
      - name: 'sns-receiver'
        sns_configs:
          - topic_arn: 'arn:aws:sns:eu-central-1:077448369105:homelab'  # TODO: Replace with your SNS Topic ARN
            sigv4:
              region: 'eu-central-1'  # TODO: Replace with your AWS region
            subject: 'Homelab Alert: {{ .GroupLabels.alertname }}'
            message: |
              {{ range .Alerts }}
              *Alert:* {{ .Labels.alertname }}
              *Severity:* {{ .Labels.severity }}
              *Summary:* {{ .Annotations.summary }}
              *Description:* {{ .Annotations.description }}
              *Details:*
              {{ range .Labels.SortedPairs }}  - {{ .Name }}: {{ .Value }}
              {{ end }}
              {{ end }}
            attributes:
              severity: '{{ .GroupLabels.severity }}'
              alertname: '{{ .GroupLabels.alertname }}'
    
    templates: []
  
  alertmanagerSpec:
    # Environment variables from AWS credentials secret
    containers:
      - name: alertmanager
        env:
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                name: alertmanager-aws-credentials
                key: AWS_ACCESS_KEY_ID
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                name: alertmanager-aws-credentials
                key: AWS_SECRET_ACCESS_KEY
          - name: AWS_REGION
            valueFrom:
              secretKeyRef:
                name: alertmanager-aws-credentials
                key: AWS_REGION
    
    resources:
      requests:
        cpu: 50m
        memory: 128Mi
      limits:
        cpu: 200m
        memory: 256Mi
    
    # Run on worker nodes only
    nodeSelector:
      node-role.kubernetes.io/worker: worker
    
    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: longhorn
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 2Gi

# Node exporter (collects node metrics)
nodeExporter:
  enabled: true

# Kube-state-metrics (cluster state metrics) - note: uses hyphens not camelCase
kube-state-metrics:
  nodeSelector:
    node-role.kubernetes.io/worker: "worker"

# Prometheus Operator
prometheusOperator:
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 500m
      memory: 512Mi
  
  # Run on worker nodes only
  nodeSelector:
    node-role.kubernetes.io/worker: worker
  
  # Enable monitoring of namespaces
  namespaces:
    releaseNamespace: true
    additional:
      - kube-system
      - ingress-nginx
      - cert-manager
      - longhorn-system
      - home-assistant
      - teslamate

# Service Monitors for additional components
additionalServiceMonitors:
  # Monitor NGINX Ingress Controller
  - name: nginx-ingress-controller
    selector:
      matchLabels:
        app.kubernetes.io/name: ingress-nginx
    namespaceSelector:
      matchNames:
        - ingress-nginx
    endpoints:
      - port: metrics
        interval: 30s
